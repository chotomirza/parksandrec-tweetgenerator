{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant values for character names\n",
    "leslie = \"Leslie Knope\"\n",
    "tom = \"Tom Haverford\"\n",
    "april = \"April Ludgate\"\n",
    "ron = \"Ron Swanson\"\n",
    "perd = \"Perd Hapley\"\n",
    "chris = \"Chris Traeger\"\n",
    "jean = \"Jean-Ralphio Saperstein\"\n",
    "characters = [leslie, tom, april, ron, perd, chris, jean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_character(character, s_token_count):\n",
    "    \"\"\"\n",
    "        Parses through csv file of all Parks and Rec dialogue, only keeping given characters dialogue\n",
    "        Each sentence is padded with s_token_count of start and end sentence tokens\n",
    "        e.g. s_token_count = 2 => [<s> <s> w1 ....  </s> </s>]\n",
    "        The sentences are shuffled so the data can be broken up into training and testing sets where data is \n",
    "        evenly spread over the entire series\n",
    "        Returns shuffled formatted sentences \n",
    "    \"\"\"\n",
    "    all_chars = open(\"sorted_name_all.csv\", newline='')\n",
    "    reader = csv.reader(all_chars, delimiter=\",\", quotechar='\"')\n",
    "    next(reader, None)\n",
    "    data = []\n",
    "    for row in reader:\n",
    "        if row[0] == character:\n",
    "            data.append(row)\n",
    "    all_chars.close()\n",
    "\n",
    "    sentences = []\n",
    "    total_count = 0\n",
    "    processed_count = 0\n",
    "    start = [\"<s>\" for i in range(s_token_count)]\n",
    "    end = [\"</s>\" for i in range(s_token_count)]\n",
    "    for line in data:\n",
    "        text = line[1].lower()\n",
    "        text = text.split()\n",
    "        clean_text = []\n",
    "        total_count += len(text)\n",
    "        for word in text:\n",
    "            no_grammar = re.sub('[^A-Za-z0-9]+', '', word)\n",
    "            if len(no_grammar) == 0:\n",
    "                continue\n",
    "            clean_text.append(no_grammar)\n",
    "        sentence = start + clean_text + end\n",
    "        sentences.append(sentence)\n",
    "    random.seed(0)\n",
    "    random.shuffle(sentences)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training/testing files for statistical model\n",
    "\n",
    "NGRAM = 4\n",
    "\n",
    "def create_data_txt(data, character):\n",
    "    \"\"\"\n",
    "        Creates training and testing data for a statistical model\n",
    "    \"\"\"\n",
    "    train = data[:2*len(data)//3]\n",
    "    test = data[2*len(data)//3:]\n",
    "    f = open(f'fourgram-{character}-train.txt', \"w\")\n",
    "    for sentence in train:\n",
    "        line = \" \".join(sentence)\n",
    "        f.write(line + '\\n')\n",
    "    f.close\n",
    "    f = open(f'fourgram-{character}-test.txt', \"w\")\n",
    "    for sentence in test:\n",
    "        line = \" \".join(sentence)\n",
    "        f.write(line + '\\n')\n",
    "    f.close\n",
    "    \n",
    "    \n",
    "def create_statistical_files():\n",
    "    for character in characters:\n",
    "        data = load_character(character, NGRAM - 1)\n",
    "        create_data_txt(data, character)\n",
    "        \n",
    "create_statistical_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN, LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.metrics import TopKCategoricalAccuracy\n",
    "from keras.initializers import Constant\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "import numpy as np \n",
    "\n",
    "def get_tokenizer_and_encoded(data):\n",
    "    \"\"\" \n",
    "        Creates a tokenizer and fits it on the given data\n",
    "        Encodes data with tokenizer\n",
    "        Returns tokenizer and encoded data\n",
    "    \"\"\"\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(data)\n",
    "    encoded = tokenizer.texts_to_sequences(data)\n",
    "    return (tokenizer, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_training_data(tokenizer, encoded):\n",
    "    \"\"\"\n",
    "        Creates training and testing data from encoded sentences\n",
    "        Breaks up sentences into sequences from w1:wN for N=1 => N=len(sentence)\n",
    "        All sequences padded with zeroes to length = max length of sentence\n",
    "        Training data is 75% of data, testing data 25%\n",
    "        Returns (trainX, trainY, testX, testY)\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    for i in range(len(encoded)):\n",
    "        encoded_sent = encoded[i]\n",
    "        for k in range(1, len(encoded_sent)):\n",
    "            x.append(encoded_sent[:k])\n",
    "            y.append(encoded_sent[k])\n",
    "\n",
    "    maxlen = max([len(sent) for sent in x])\n",
    "    x = np.array([pad_sequences([sent], maxlen=maxlen, padding='pre')[0] for sent in x])\n",
    "    y = np.array(y)\n",
    "    y = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "    trainX = x[:3*len(x)//4]\n",
    "    trainY = y[:3*len(x)//4]\n",
    "    testX = x[3*len(y)//4:]\n",
    "    testY = y[3*len(y)//4:]\n",
    "    return (trainX, trainY, testX, testY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, maxlen):\n",
    "    \"\"\"\n",
    "        Creates RNN model with Embedding, LSTM, and softmax layers\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 200, input_length=maxlen))\n",
    "    model.add(LSTM(400))\n",
    "    model.add(Dense(vocab_size, activation='softmax')) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trainX, trainY, model):\n",
    "    \"\"\"\n",
    "        Trains given model on given data\n",
    "    \"\"\"\n",
    "    acc = TopKCategoricalAccuracy(k=5)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[acc, \"accuracy\"])\n",
    "    model.fit(trainX, trainY, epochs=25, batch_size=256)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_word(tokenizer):\n",
    "    index_to_word_dict = {}\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        index_to_word_dict[index] = word\n",
    "    return index_to_word_dict\n",
    "\n",
    "def generate_text(seed, max_words, model, maxlen, n, tokenizer, index_to_word):\n",
    "    \"\"\" \n",
    "        Generates n sentences with max length max_words. Uses given seed to begin generating words. \n",
    "        Returns sentences\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    while len(output) < n:\n",
    "        seed_text = seed\n",
    "        for _ in range(max_words):\n",
    "            token_list = [tokenizer.word_index[word] for word in seed_text.split()]\n",
    "            token_list = pad_sequences([token_list], maxlen=maxlen, padding='pre')\n",
    "            prediction  = model.predict([token_list])[0]\n",
    "            index = np.random.choice(len(prediction), p=prediction)\n",
    "            \n",
    "            if index == 0:\n",
    "                continue\n",
    "            \n",
    "            predicted_word = index_to_word[index]\n",
    "            seed_text += \" \" + predicted_word\n",
    "            if predicted_word == \"</s>\":\n",
    "                break\n",
    "            if len(seed_text) > 147:\n",
    "                break\n",
    "        if len(seed_text) < 15:\n",
    "            continue\n",
    "        output.append(seed_text)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(character, sentences):\n",
    "    \"\"\"\n",
    "        Saves generated sentences to file for specific character\n",
    "    \"\"\"\n",
    "    f = open(f'{character}-rnn-sentences.txt', \"w\")\n",
    "    for sentence in sentences:\n",
    "        f.write(sentence+'\\n')\n",
    "    f.close()\n",
    "\n",
    "def create_and_train_model(character):\n",
    "    \"\"\"\n",
    "        Loads data, trains model, and generates 50 sentences for specific character\n",
    "    \"\"\"\n",
    "    print(\"CHARACTER:\", character)\n",
    "    \n",
    "    data = load_character(character, 1)\n",
    "    tokenizer, encoded = get_tokenizer_and_encoded(data)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    trainX, trainY, testX, testY = get_training_data(tokenizer, encoded)\n",
    "    maxlen = len(trainX[0])\n",
    "    \n",
    "    model = create_model(vocab_size, maxlen)\n",
    "    train_model(trainX, trainY, model)\n",
    "    \n",
    "    results = model.evaluate(testX, testY, batch_size=256)\n",
    "    print(f'Results - Loss: {results[0]}, Top-K Accuracy: {results[1]}, Accuracy:{results[2]} ')\n",
    "    \n",
    "    \n",
    "    index_to_word_dict = index_to_word(tokenizer)\n",
    "    text = generate_text(\"<s>\", 40, model, maxlen, 50, tokenizer, index_to_word_dict)\n",
    "    \n",
    "    save(character, text)\n",
    "    name = character.split()\n",
    "    model.save(name[0])\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHARACTER: Leslie Knope\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-4a28c2a9af7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Intentionally breaking up model creation and training for each character\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Easier to understand the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcreate_and_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleslie\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-e403345f69a9>\u001b[0m in \u001b[0;36mcreate_and_train_model\u001b[0;34m(character)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_and_encoded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-f15ac6189015>\u001b[0m in \u001b[0;36mget_training_data\u001b[0;34m(tokenizer, encoded)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pre'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-f15ac6189015>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pre'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m    154\u001b[0m           \u001b[0;32mor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mof\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m   return sequence.pad_sequences(\n\u001b[0m\u001b[1;32m    157\u001b[0m       \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m       padding=padding, truncating=truncating, value=value)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# check `trunc` has expected shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mtrunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             raise ValueError('Shape of sample %s of sequence at position %s '\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Intentionally breaking up model creation and training for each character \n",
    "# Easier to understand the results\n",
    "create_and_train_model(leslie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_train_model(tom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_train_model(april)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_train_model(ron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHARACTER: Perd Hapley\n",
      "Epoch 1/2\n",
      "6/6 [==============================] - 3s 267ms/step - loss: 6.3399 - top_k_categorical_accuracy: 0.0948 - accuracy: 0.0566\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 2s 293ms/step - loss: 5.6209 - top_k_categorical_accuracy: 0.1821 - accuracy: 0.0870\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f860139a040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f860139a040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 97ms/step - loss: 5.7862 - top_k_categorical_accuracy: 0.2222 - accuracy: 0.0959\n",
      "Results - Loss: 5.786198616027832, Top-K Accuracy: 0.2222222238779068, Accuracy:0.0958605632185936 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Perd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Perd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s> is ya been i that one didnt you the show thing leslie almost horse of piece and jen gonna is called defendant is box real sense </s>', '<s> to you at one is is show having will there with department deputy we to some the an greatest begins films a two been what like well ive a our a heard', '<s> tonight not a unconfirmed is with hosting story points thats im </s>', '<s> and vote a talking story and to i evening you four 35 begin watering microphone </s>', '<s> half joke department show </s>', '<s> strong well </s>', '<s> word seconds return this knope right this a jamm is misplaced i tonight stop story is define a a </s>', '<s> first ive a a </s>', '<s> of which unconfirmed </s>', '<s> and of name story at knope well a our </s>', '<s> one going the question a brandi gokart whats did gonna abstinence </s>', '<s> show to box revelation in the wont knope two we that the also break go im trying go jobs to and that are your the </s>', '<s> adult you dance the </s>', '<s> 200 et i situation rockumentary </s>', '<s> box court now of not that what mouth our appeal well the press bandits the some 100 you there by is series a scandal </s>', '<s> not as i the back to a of everyone ask name is </s>', '<s> statement bit i i first </s>', '<s> hapley is you </s>', '<s> judge i term stars reporting a time of </s>', '<s> when back my the is interim </s>', '<s> is now of situation it to and a campaign your youve tap about et they commercial would with paper situation the knope named the the to of a a today', '<s> calling if 35 time your a in knope maxxxx your she by to this would reporter that heard to to even a what the also </s>', '<s> the full and i now i about the a department said this is a three and his you prefer statement and thing biggest is of the thing my some unexpected', '<s> to 78 well in wyatt good </s>', '<s> like and welcome word in question now one channel want break perd a stumped of </s>', '<s> called city to now press thank going now to story number gonna infestation message this of hear is to a this </s>', '<s> of one is is a isnt story of beloved after to leslie leslie to hap the female was little is harvest 200 </s>', '<s> roscoe we cadence thinner to to back is journalistic you coverage you is is is that to 1 192 such a its judge no sorry answer </s>', '<s> number us jamm 200 honest strong the blazer eyewitness </s>', '<s> had leslie medium a newport in of of court perd words one horse </s>', '<s> this words mayor if see jen thing is a to 78 the leslie be campaign woman perd latest update to time sweetums knope cannot and the is business fans', '<s> separately and animation real to answer something of a a city perd now </s>', '<s> on in today 35 </s>', '<s> its actual answer the words good a closing a are i perd your turn story glass brandi about just leslie also strong story jobs perd perspective leslie', '<s> return perd you we to </s>', '<s> controversial going </s>', '<s> with with hapley verdict interim are amateur live now even director with </s>', '<s> yet be thing </s>', '<s> of the but tonight time hapley personal not to around </s>', '<s> a now an i here name is beloved leslie starred you his glass to of and to the allegations prefer </s>', '<s> hapley poll coverage infestation eyewitness the knope nothing hapley is </s>', '<s> a a and vote with stars thing leslie show time would gryzzl say this when the big of to misplaced go word i thinner to they going </s>', '<s> are on director of 15 four the is isnt our the knope the say program that the </s>', '<s> it points and perd 200 our youve how </s>', '<s> our my our after about in okay well introduce recreation its is city see film show who </s>', '<s> with a and might you to the according dexhart a event this is be verdict his </s>', '<s> on the like one an to the is no coverage question to support of a what words of number you and dirt show you is hear vote of mayor im pawnee a back', '<s> you and your </s>', '<s> program city has </s>', '<s> are going hello 35 i councilman the the is a show the a call controversial also and votes real of mouse votes an by is this candy council in integrity']\n"
     ]
    }
   ],
   "source": [
    "create_and_train_model(perd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_train_model(chris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_train_model(jean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistical_model import LanguageModel, test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_stat_model(character):\n",
    "    lm = LanguageModel(4, True)\n",
    "    lm.train(f'fourgram-{character}-train.txt')\n",
    "    test_model(lm, f'fourgram-{character}-test.txt', character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Leslie Knope\n",
      "Sentences:\n",
      "<s> <s> <s> no you have to be better </s> </s> </s>\n",
      "<s> <s> <s> and you have every right to be but were hoping what were gonna do this </s> </s> </s>\n",
      "<s> <s> <s> youve never had a budget shortage </s> </s> </s>\n",
      "<s> <s> <s> yeah </s> </s> </s>\n",
      "<s> <s> <s> ann you <UNK> bastard </s> </s> </s>\n",
      "<s> <s> <s> i knew it </s> </s> </s>\n",
      "<s> <s> <s> the interview is back on </s> </s> </s>\n",
      "<s> <s> <s> okay we have a new item up for bid is two <UNK> vip passes to the unity concert </s> </s> </s>\n",
      "<s> <s> <s> no more <UNK> in modern society and theyre embarrassing to pawnee </s> </s> </s>\n",
      "<s> <s> <s> i dont really trust these guys </s> </s> </s>\n",
      "<s> <s> <s> sorry </s> </s> </s>\n",
      "<s> <s> <s> i wouldnt wish it on my <UNK> i held the position of deputy director of parks and recreation department </s> </s> </s>\n",
      "<s> <s> <s> okay </s> </s> </s>\n",
      "<s> <s> <s> just one item jennifer </s> </s> </s>\n",
      "<s> <s> <s> this is a little fun i was having you know </s> </s> </s>\n",
      "<s> <s> <s> think fast </s> </s> </s>\n",
      "<s> <s> <s> <UNK> <UNK> ann </s> </s> </s>\n",
      "<s> <s> <s> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> or get your <UNK> out or get your handkerchiefs out </s> </s> </s>\n",
      "<s> <s> <s> <UNK> left </s> </s> </s>\n",
      "<s> <s> <s> well howser is with me </s> </s> </s>\n",
      "<s> <s> <s> no no </s> </s> </s>\n",
      "<s> <s> <s> this is <UNK> irregular </s> </s> </s>\n",
      "<s> <s> <s> now if youll excuse me im about endorse ten beers into my mouth cause this has been a question <UNK> about when my relationship with ben wyatt ended </s> </s> </s>\n",
      "<s> <s> <s> <UNK> you like <UNK> on ann from the pit </s> </s> </s>\n",
      "<s> <s> <s> oh i already know the one on the left where the american flag is </s> </s> </s>\n",
      "<s> <s> <s> well the <UNK> was amazing </s> </s> </s>\n",
      "<s> <s> <s> im so glad that youre here </s> </s> </s>\n",
      "<s> <s> <s> what i want </s> </s> </s>\n",
      "<s> <s> <s> just for fun </s> </s> </s>\n",
      "<s> <s> <s> and thats why this is a dream come true </s> </s> </s>\n",
      "<s> <s> <s> i called <UNK> </s> </s> </s>\n",
      "<s> <s> <s> and were here to get you clean </s> </s> </s>\n",
      "<s> <s> <s> just talk about this </s> </s> </s>\n",
      "<s> <s> <s> sure </s> </s> </s>\n",
      "<s> <s> <s> oh <UNK> im as disappointed as you are herb </s> </s> </s>\n",
      "<s> <s> <s> what are you doing for your birthday on friday </s> </s> </s>\n",
      "<s> <s> <s> ron were being very careful </s> </s> </s>\n",
      "<s> <s> <s> why would he do that </s> </s> </s>\n",
      "<s> <s> <s> just give me a minute here please </s> </s> </s>\n",
      "<s> <s> <s> donna </s> </s> </s>\n",
      "<s> <s> <s> it doesnt make any sense </s> </s> </s>\n",
      "<s> <s> <s> water im sorry </s> </s> </s>\n",
      "<s> <s> <s> im a <UNK> </s> </s> </s>\n",
      "<s> <s> <s> its almost 600 in the morning </s> </s> </s>\n",
      "<s> <s> <s> oh my </s> </s> </s>\n",
      "<s> <s> <s> whos next </s> </s> </s>\n",
      "<s> <s> <s> work that often goes <UNK> </s> </s> </s>\n",
      "<s> <s> <s> everybody give em money </s> </s> </s>\n",
      "<s> <s> <s> perfect </s> </s> </s> \n",
      "\n",
      "test corpus:  fourgram-Leslie Knope-test.txt\n",
      "# of test sentences: 6029\n",
      "Average probability: 1.211735113326185e-07\n",
      "Standard deviation: 6.710178392987407e-07\n"
     ]
    }
   ],
   "source": [
    "create_and_train_stat_model(leslie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Tom Haverford\n",
      "Sentences:\n",
      "<s> <s> <s> well jerry what the hell </s> </s> </s>\n",
      "<s> <s> <s> we gotta send this dude off with the perfect gift </s> </s> </s>\n",
      "<s> <s> <s> are we saying <UNK> anytime we think <UNK> dope </s> </s> </s>\n",
      "<s> <s> <s> listening to that tree lighting is gonna be fine </s> </s> </s>\n",
      "<s> <s> <s> okay </s> </s> </s>\n",
      "<s> <s> <s> yeah jessica is a gold digger digger </s> </s> </s>\n",
      "<s> <s> <s> what the hell jerry </s> </s> </s>\n",
      "<s> <s> <s> no </s> </s> </s>\n",
      "<s> <s> <s> i own my own restaurant and several other properties </s> </s> </s>\n",
      "<s> <s> <s> <UNK> <UNK> <UNK> <UNK> martin and bruno mars </s> </s> </s>\n",
      "<s> <s> <s> ill think of ideas in the tree </s> </s> </s>\n",
      "<s> <s> <s> <UNK> a phone that smells good </s> </s> </s>\n",
      "<s> <s> <s> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> they had a <UNK> </s> </s> </s>\n",
      "<s> <s> <s> <UNK> you want </s> </s> </s>\n",
      "<s> <s> <s> tom <UNK> in the <UNK> </s> </s> </s>\n",
      "<s> <s> <s> nice job man </s> </s> </s>\n",
      "<s> <s> <s> what can i say </s> </s> </s>\n",
      "<s> <s> <s> i must be the <UNK> </s> </s> </s>\n",
      "<s> <s> <s> whos this person </s> </s> </s>\n",
      "<s> <s> <s> your mysterious <UNK> client seems like a pretty <UNK> guy </s> </s> </s>\n",
      "<s> <s> <s> i dont mind hooking you up </s> </s> </s>\n",
      "<s> <s> <s> i dont want to <UNK> that </s> </s> </s>\n",
      "<s> <s> <s> wow dont be such a jerry ben </s> </s> </s>\n",
      "<s> <s> <s> im opening pawnees first authentic <UNK> style italian restaurant toms bistro </s> </s> </s>\n",
      "<s> <s> <s> so as you all know </s> </s> </s>\n",
      "<s> <s> <s> thanks </s> </s> </s>\n",
      "<s> <s> <s> easy for you to say </s> </s> </s>\n",
      "<s> <s> <s> all this lying about me <UNK> now </s> </s> </s>\n",
      "<s> <s> <s> we have not one but six open bars </s> </s> </s>\n",
      "<s> <s> <s> i didnt mean me </s> </s> </s>\n",
      "<s> <s> <s> right </s> </s> </s>\n",
      "<s> <s> <s> im a mogul now </s> </s> </s>\n",
      "<s> <s> <s> half your age plus seven </s> </s> </s>\n",
      "<s> <s> <s> what if we took every <UNK> we had left threw one last party </s> </s> </s>\n",
      "<s> <s> <s> we have <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> if she <UNK> me tell jeanralphio to clear my <UNK> history </s> </s> </s>\n",
      "<s> <s> <s> the four <UNK> words in the <UNK> <UNK> <UNK> milk </s> </s> </s>\n",
      "<s> <s> <s> i gotta meet up with an old friend </s> </s> </s>\n",
      "<s> <s> <s> eventually monalisa threw a <UNK> through the girls <UNK> </s> </s> </s>\n",
      "<s> <s> <s> sorry monalisa </s> </s> </s>\n",
      "<s> <s> <s> lets hit it donna </s> </s> </s>\n",
      "<s> <s> <s> we have this place for one more night right </s> </s> </s>\n",
      "<s> <s> <s> youre ejected too </s> </s> </s>\n",
      "<s> <s> <s> i was born to do </s> </s> </s>\n",
      "<s> <s> <s> youre perfect each and every one of you has to tell him the truth </s> </s> </s>\n",
      "<s> <s> <s> well im sorry your face just isnt working </s> </s> </s>\n",
      "<s> <s> <s> ah </s> </s> </s>\n",
      "<s> <s> <s> excuse me </s> </s> </s>\n",
      "<s> <s> <s> which time </s> </s> </s> \n",
      "\n",
      "test corpus:  fourgram-Tom Haverford-test.txt\n",
      "# of test sentences: 2096\n",
      "Average probability: 1.3239214158570295e-07\n",
      "Standard deviation: 1.0164529914582596e-06\n"
     ]
    }
   ],
   "source": [
    "create_and_train_stat_model(tom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: April Ludgate\n",
      "Sentences:\n",
      "<s> <s> <s> you <UNK> me <UNK> i swear to god my arms cant move that way </s> </s> </s>\n",
      "<s> <s> <s> check your <UNK> </s> </s> </s>\n",
      "<s> <s> <s> yeah he does being a <UNK> and a three car <UNK> </s> </s> </s>\n",
      "<s> <s> <s> because this prom reminds me that you would be the worst person ive ever met </s> </s> </s>\n",
      "<s> <s> <s> i just heard one <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> yeah i just had a gut feeling that it wasnt right for me then nothing is </s> </s> </s>\n",
      "<s> <s> <s> no </s> </s> </s>\n",
      "<s> <s> <s> your kids are like <UNK> awesome </s> </s> </s>\n",
      "<s> <s> <s> i think youre fine </s> </s> </s>\n",
      "<s> <s> <s> yay </s> </s> </s>\n",
      "<s> <s> <s> how does this sound officer dwyer pawnee <UNK> </s> </s> </s>\n",
      "<s> <s> <s> fine then ill make out with three <UNK> <UNK> make out with him when im drunk sometimes </s> </s> </s>\n",
      "<s> <s> <s> god shes always just leaving and not telling me </s> </s> </s>\n",
      "<s> <s> <s> is it like a <UNK> how long it takes to get here </s> </s> </s>\n",
      "<s> <s> <s> ew </s> </s> </s>\n",
      "<s> <s> <s> i only <UNK> to come back here because of our deal </s> </s> </s>\n",
      "<s> <s> <s> ill make sure you dont have to <UNK> an <UNK> <UNK> with extra extra <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> okay could you just skip ahead a little </s> </s> </s>\n",
      "<s> <s> <s> <UNK> god no one <UNK> the word <UNK> anymore </s> </s> </s>\n",
      "<s> <s> <s> what do i do if working around <UNK> isnt even right for me thats all </s> </s> </s>\n",
      "<s> <s> <s> can you handle like 20 <UNK> or a <UNK> <UNK> with a glass of your most expensive red wine <UNK> with a terrible secret </s> </s> </s>\n",
      "<s> <s> <s> why does she need our help </s> </s> </s>\n",
      "<s> <s> <s> no </s> </s> </s>\n",
      "<s> <s> <s> i cant do anything </s> </s> </s>\n",
      "<s> <s> <s> what do you think </s> </s> </s>\n",
      "<s> <s> <s> we cant let them <UNK> us </s> </s> </s>\n",
      "<s> <s> <s> is there anything else to eat the <UNK> if we can get one </s> </s> </s>\n",
      "<s> <s> <s> um you also work there </s> </s> </s>\n",
      "<s> <s> <s> i just stole your phone and <UNK> every guy in it all the time off the top of your head </s> </s> </s>\n",
      "<s> <s> <s> watch this </s> </s> </s>\n",
      "<s> <s> <s> dude 30 years from now when youre on your <UNK> what are you doing weirdo </s> </s> </s>\n",
      "<s> <s> <s> and i start in a couple months </s> </s> </s>\n",
      "<s> <s> <s> looking at me like a crazy person </s> </s> </s>\n",
      "<s> <s> <s> um i miss andy </s> </s> </s>\n",
      "<s> <s> <s> ron you want to do things </s> </s> </s>\n",
      "<s> <s> <s> thats not possible </s> </s> </s>\n",
      "<s> <s> <s> none of his <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> no </s> </s> </s>\n",
      "<s> <s> <s> thats why im so lively and colorful </s> </s> </s>\n",
      "<s> <s> <s> do you think </s> </s> </s>\n",
      "<s> <s> <s> hey </s> </s> </s>\n",
      "<s> <s> <s> no </s> </s> </s>\n",
      "<s> <s> <s> its weird </s> </s> </s>\n",
      "<s> <s> <s> yeah jerry its probably a <UNK> because it needed water and i thought it would just drink out of the toilet or something but then it ran off and i couldnt get it back in </s> </s> </s>\n",
      "<s> <s> <s> his <UNK> around the office is <UNK> <UNK> house </s> </s> </s>\n",
      "<s> <s> <s> hey </s> </s> </s>\n",
      "<s> <s> <s> eww </s> </s> </s>\n",
      "<s> <s> <s> wow there he is </s> </s> </s>\n",
      "<s> <s> <s> what do you think you could come back today at <UNK> hes available then </s> </s> </s>\n",
      "<s> <s> <s> theyre important to you </s> </s> </s> \n",
      "\n",
      "test corpus:  fourgram-April Ludgate-test.txt\n",
      "# of test sentences: 1209\n",
      "Average probability: 2.5265052991993494e-07\n",
      "Standard deviation: 1.1627139483958766e-06\n"
     ]
    }
   ],
   "source": [
    "create_and_train_stat_model(april)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Perd Hapley\n",
      "Sentences:\n",
      "<s> <s> <s> <UNK> <UNK> would you <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> the story of this story <UNK> even more <UNK> </s> </s> </s>\n",
      "<s> <s> <s> <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> and its razor <UNK> and <UNK> and even <UNK> glass </s> </s> </s>\n",
      "<s> <s> <s> theyre <UNK> theyre <UNK> but now theyre <UNK> <UNK> at the <UNK> little <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> and our <UNK> poll <UNK> to <UNK> <UNK> in the pawnee <UNK> the <UNK> </s> </s> </s>\n",
      "<s> <s> <s> the story of this situation is its <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> and leslie knope closing statement </s> </s> </s>\n",
      "<s> <s> <s> <UNK> show <UNK> now </s> </s> </s>\n",
      "<s> <s> <s> the story of this story <UNK> even more <UNK> </s> </s> </s>\n",
      "<s> <s> <s> there are some <UNK> that id like to ask you about the <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> there is <UNK> a thing as <UNK> integrity and it is <UNK> that i have as a <UNK> with integrity </s> </s> </s>\n",
      "<s> <s> <s> here to answer this question is parks and recreation </s> </s> </s>\n",
      "<s> <s> <s> thats the name i call fans of this show <UNK> on the <UNK> we <UNK> from you our fans in our new segment are you there perdverts its me perd <UNK> a new segment </s> </s> </s>\n",
      "<s> <s> <s> its judge perd </s> </s> </s>\n",
      "<s> <s> <s> good evening </s> </s> </s>\n",
      "<s> <s> <s> <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> wow </s> </s> </s>\n",
      "<s> <s> <s> and i would just like an <UNK> glass </s> </s> </s>\n",
      "<s> <s> <s> i do have an update on your time <UNK> and that update is that your time is <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> there is <UNK> a thing as <UNK> integrity and it is <UNK> that i have as a <UNK> with integrity </s> </s> </s>\n",
      "<s> <s> <s> wow <UNK> words from a <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> to be <UNK> judge perd is <UNK> by this <UNK> </s> </s> </s>\n",
      "<s> <s> <s> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> good evening </s> </s> </s>\n",
      "<s> <s> <s> <UNK> words but this reporter does <UNK> those <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> from the city council </s> </s> </s>\n",
      "<s> <s> <s> is not a <UNK> i will be saying to you right now </s> </s> </s>\n",
      "<s> <s> <s> and the story of this situation is its <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> <UNK> <UNK> would you <UNK> <UNK> the newport plan to the knope plan </s> </s> </s>\n",
      "<s> <s> <s> <UNK> i <UNK> declare a <UNK> which is a <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> the <UNK> gryzzl <UNK> <UNK> <UNK> to be a <UNK> big <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> wow </s> </s> </s>\n",
      "<s> <s> <s> were <UNK> be back with our closing <UNK> right after a <UNK> from our <UNK> sweetums pawnees <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> and <UNK> and even <UNK> glass </s> </s> </s>\n",
      "<s> <s> <s> mayor <UNK> what are your <UNK> for your first <UNK> term </s> </s> </s>\n",
      "<s> <s> <s> perd <UNK> </s> </s> </s>\n",
      "<s> <s> <s> <UNK> like the <UNK> in the pawnee <UNK> the <UNK> </s> </s> </s>\n",
      "<s> <s> <s> <UNK> the statement that this reporter has is a question </s> </s> </s>\n",
      "<s> <s> <s> welcome to ya heard </s> </s> </s>\n",
      "<s> <s> <s> <UNK> me a little <UNK> about leslie knope </s> </s> </s>\n",
      "<s> <s> <s> from the city council </s> </s> </s>\n",
      "<s> <s> <s> were <UNK> be back with our closing <UNK> right after a <UNK> from our <UNK> sweetums pawnees <UNK> <UNK> of candy and <UNK> </s> </s> </s>\n",
      "<s> <s> <s> i dont know <UNK> </s> </s> </s>\n",
      "<s> <s> <s> we begin with our first story tonight </s> </s> </s>\n",
      "<s> <s> <s> but <UNK> you had the answer i would have <UNK> is <UNK> </s> </s> </s>\n",
      "<s> <s> <s> from the city council </s> </s> </s>\n",
      "<s> <s> <s> well the story of this next <UNK> is that its <UNK> the <UNK> </s> </s> </s> \n",
      "\n",
      "test corpus:  fourgram-Perd Hapley-test.txt\n",
      "# of test sentences: 56\n",
      "Average probability: 4.092676524329279e-08\n",
      "Standard deviation: 2.9945775186971093e-07\n"
     ]
    }
   ],
   "source": [
    "create_and_train_stat_model(perd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Ron Swanson\n",
      "Sentences:\n",
      "<s> <s> <s> shes a <UNK> a bitch </s> </s> </s>\n",
      "<s> <s> <s> lets get to the <UNK> </s> </s> </s>\n",
      "<s> <s> <s> here you are </s> </s> </s>\n",
      "<s> <s> <s> i just gave her the day off </s> </s> </s>\n",
      "<s> <s> <s> and yes i will absolutely go back to get my shoes <UNK> soon </s> </s> </s>\n",
      "<s> <s> <s> another stupid government rule </s> </s> </s>\n",
      "<s> <s> <s> spending the day outside alone sounds like a dream </s> </s> </s>\n",
      "<s> <s> <s> you know what makes a good person does something bad they own up to it </s> </s> </s>\n",
      "<s> <s> <s> i just <UNK> there <UNK> breathing </s> </s> </s>\n",
      "<s> <s> <s> lets go son </s> </s> </s>\n",
      "<s> <s> <s> and soon itll have to </s> </s> </s>\n",
      "<s> <s> <s> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> nice </s> </s> </s>\n",
      "<s> <s> <s> i think youre being hard on yourself </s> </s> </s>\n",
      "<s> <s> <s> tommy boy </s> </s> </s>\n",
      "<s> <s> <s> its <UNK> </s> </s> </s>\n",
      "<s> <s> <s> i dont know what you did to em but it worked like <UNK> </s> </s> </s>\n",
      "<s> <s> <s> why </s> </s> </s>\n",
      "<s> <s> <s> itll be damn hard to replace you </s> </s> </s>\n",
      "<s> <s> <s> shes ejected </s> </s> </s>\n",
      "<s> <s> <s> <UNK> every single word out of their <UNK> was a lie </s> </s> </s>\n",
      "<s> <s> <s> money <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> okay </s> </s> </s>\n",
      "<s> <s> <s> paul if you ever see another one of these women is running a <UNK> <UNK> sugar <UNK> </s> </s> </s>\n",
      "<s> <s> <s> ive used the same wooden <UNK> for three decades </s> </s> </s>\n",
      "<s> <s> <s> although if youd like to visit europe i like you so much </s> </s> </s>\n",
      "<s> <s> <s> apparently <UNK> <UNK> wants me to do </s> </s> </s>\n",
      "<s> <s> <s> epic and private </s> </s> </s>\n",
      "<s> <s> <s> and <UNK> okay and <UNK> terrible </s> </s> </s>\n",
      "<s> <s> <s> made from the <UNK> of <UNK> cologne and a <UNK> porterhouse </s> </s> </s>\n",
      "<s> <s> <s> where is this lawyer you speak of </s> </s> </s>\n",
      "<s> <s> <s> its <UNK> having you just sit there </s> </s> </s>\n",
      "<s> <s> <s> what other <UNK> of me drinking the whiskey </s> </s> </s>\n",
      "<s> <s> <s> although i expect a <UNK> debate with leslie </s> </s> </s>\n",
      "<s> <s> <s> its art </s> </s> </s>\n",
      "<s> <s> <s> its just a bleep fish </s> </s> </s>\n",
      "<s> <s> <s> i like to call them by the wrong name to let them know i dont really care about them </s> </s> </s>\n",
      "<s> <s> <s> whats <UNK> </s> </s> </s>\n",
      "<s> <s> <s> we have nothing to eat </s> </s> </s>\n",
      "<s> <s> <s> <UNK> put the <UNK> down </s> </s> </s>\n",
      "<s> <s> <s> move </s> </s> </s>\n",
      "<s> <s> <s> it was a good chair </s> </s> </s>\n",
      "<s> <s> <s> felt like i had a good run here </s> </s> </s>\n",
      "<s> <s> <s> salvatore was a <UNK> mark on a <UNK> </s> </s> </s>\n",
      "<s> <s> <s> but i havent had much luck finding a <UNK> </s> </s> </s>\n",
      "<s> <s> <s> there will be no fun at all </s> </s> </s>\n",
      "<s> <s> <s> the open house is now closed </s> </s> </s>\n",
      "<s> <s> <s> im a libertarian </s> </s> </s>\n",
      "<s> <s> <s> okay everybody </s> </s> </s>\n",
      "<s> <s> <s> thats a kind offer andrew but i wont be playing </s> </s> </s> \n",
      "\n",
      "test corpus:  fourgram-Ron Swanson-test.txt\n",
      "# of test sentences: 1665\n",
      "Average probability: 2.8062393095897053e-08\n",
      "Standard deviation: 2.5219938230762143e-07\n"
     ]
    }
   ],
   "source": [
    "create_and_train_stat_model(ron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Chris Traeger\n",
      "Sentences:\n",
      "<s> <s> <s> get in on this </s> </s> </s>\n",
      "<s> <s> <s> was that ann </s> </s> </s>\n",
      "<s> <s> <s> im going to do </s> </s> </s>\n",
      "<s> <s> <s> you know the old chris wouldve loved this super <UNK> health <UNK> and i feel like we should ask for an <UNK> to stay here </s> </s> </s>\n",
      "<s> <s> <s> let me take you there and you can talk to the <UNK> of whats going on with me and <UNK> daughter and i thought id <UNK> up and say hi </s> </s> </s>\n",
      "<s> <s> <s> leslie and ben are engaged </s> </s> </s>\n",
      "<s> <s> <s> im so excited to be working with you all again </s> </s> </s>\n",
      "<s> <s> <s> and did you use it </s> </s> </s>\n",
      "<s> <s> <s> you caught me before my first run of the day </s> </s> </s>\n",
      "<s> <s> <s> i know </s> </s> </s>\n",
      "<s> <s> <s> i know who im gonna use to <UNK> <UNK> and my <UNK> is the size of a <UNK> <UNK> to her and tell her i will not break it a <UNK> </s> </s> </s>\n",
      "<s> <s> <s> that said the show was pretty <UNK> </s> </s> </s>\n",
      "<s> <s> <s> you know the meeting that ben and i are very <UNK> people and we have often been at <UNK> </s> </s> </s>\n",
      "<s> <s> <s> im so excited to be working with you all again </s> </s> </s>\n",
      "<s> <s> <s> its quite small </s> </s> </s>\n",
      "<s> <s> <s> oh sorry </s> </s> </s>\n",
      "<s> <s> <s> this isnt anything like your affair with tom haverford </s> </s> </s>\n",
      "<s> <s> <s> i am part of the problem </s> </s> </s>\n",
      "<s> <s> <s> i think </s> </s> </s>\n",
      "<s> <s> <s> yeah </s> </s> </s>\n",
      "<s> <s> <s> look <UNK> we are here to <UNK> with your budget </s> </s> </s>\n",
      "<s> <s> <s> because i no longer trust anything other than my own two hands </s> </s> </s>\n",
      "<s> <s> <s> do not buy orange </s> </s> </s>\n",
      "<s> <s> <s> with <UNK> like you like the amazing person that you are <UNK> <UNK> <UNK> and i <UNK> after champion here </s> </s> </s>\n",
      "<s> <s> <s> youll be amazing at it and the best part there is no <UNK> hearing </s> </s> </s>\n",
      "<s> <s> <s> oh i disagree </s> </s> </s>\n",
      "<s> <s> <s> id like them in <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> im sorry that i <UNK> five years to your life </s> </s> </s>\n",
      "<s> <s> <s> hey guys </s> </s> </s>\n",
      "<s> <s> <s> ive had a <UNK> </s> </s> </s>\n",
      "<s> <s> <s> is one better </s> </s> </s>\n",
      "<s> <s> <s> its a very special day </s> </s> </s>\n",
      "<s> <s> <s> i <UNK> <UNK> best qualities and then i find someone else with <UNK> qualities and i bring them together </s> </s> </s>\n",
      "<s> <s> <s> <UNK> we learn the most about <UNK> through the <UNK> </s> </s> </s>\n",
      "<s> <s> <s> look at us </s> </s> </s>\n",
      "<s> <s> <s> i dont know why </s> </s> </s>\n",
      "<s> <s> <s> im not crazy </s> </s> </s>\n",
      "<s> <s> <s> i agree </s> </s> </s>\n",
      "<s> <s> <s> it used to be when i was down i called my running coach </s> </s> </s>\n",
      "<s> <s> <s> it says here that some men <UNK> <UNK> weight when their partners get pregnant </s> </s> </s>\n",
      "<s> <s> <s> so it needs to be <UNK> friends with </s> </s> </s>\n",
      "<s> <s> <s> i went to jamms with you because i also want to leave the right kind of <UNK> and <UNK> white </s> </s> </s>\n",
      "<s> <s> <s> thats a healthier option </s> </s> </s>\n",
      "<s> <s> <s> now theres not </s> </s> </s>\n",
      "<s> <s> <s> oh god ron </s> </s> </s>\n",
      "<s> <s> <s> the <UNK> possible thing we could do would be to stop because if the campaign <UNK> we all stop </s> </s> </s>\n",
      "<s> <s> <s> the indiana little <UNK> <UNK> <UNK> <UNK> times a night </s> </s> </s>\n",
      "<s> <s> <s> ben this is your night </s> </s> </s>\n",
      "<s> <s> <s> hi </s> </s> </s>\n",
      "<s> <s> <s> whats up with you </s> </s> </s> \n",
      "\n",
      "test corpus:  fourgram-Chris Traeger-test.txt\n",
      "# of test sentences: 945\n",
      "Average probability: 1.463310266457513e-07\n",
      "Standard deviation: 9.80297634490569e-07\n"
     ]
    }
   ],
   "source": [
    "create_and_train_stat_model(chris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Jean-Ralphio Saperstein\n",
      "Sentences:\n",
      "<s> <s> <s> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> that should be enough right </s> </s> </s>\n",
      "<s> <s> <s> im gonna have a <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> i heard <UNK> of <UNK> </s> </s> </s>\n",
      "<s> <s> <s> what do you say you and i get <UNK> in a <UNK> way </s> </s> </s>\n",
      "<s> <s> <s> i cant do this <UNK> you </s> </s> </s>\n",
      "<s> <s> <s> <UNK> should be coming to us </s> </s> </s>\n",
      "<s> <s> <s> this guy <UNK> in </s> </s> </s>\n",
      "<s> <s> <s> six gs </s> </s> </s>\n",
      "<s> <s> <s> what the <UNK> is but when you <UNK> it can you take care of it for us </s> </s> </s>\n",
      "<s> <s> <s> uhoh </s> </s> </s>\n",
      "<s> <s> <s> <UNK> with <UNK> </s> </s> </s>\n",
      "<s> <s> <s> no way </s> </s> </s>\n",
      "<s> <s> <s> and those guys are <UNK> out <UNK> <UNK> with my <UNK> </s> </s> </s>\n",
      "<s> <s> <s> that is unbelievable but listen to me listen to me </s> </s> </s>\n",
      "<s> <s> <s> you <UNK> to stop by </s> </s> </s>\n",
      "<s> <s> <s> <UNK> it </s> </s> </s>\n",
      "<s> <s> <s> that makes <UNK> </s> </s> </s>\n",
      "<s> <s> <s> go my puppets </s> </s> </s>\n",
      "<s> <s> <s> it is </s> </s> </s>\n",
      "<s> <s> <s> that should be enough right </s> </s> </s>\n",
      "<s> <s> <s> will you do me one <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> huh </s> </s> </s>\n",
      "<s> <s> <s> a lot <UNK> on this </s> </s> </s>\n",
      "<s> <s> <s> you <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> <UNK> baby </s> </s> </s>\n",
      "<s> <s> <s> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> i say why dont we cut our <UNK> if it was <UNK> a good idea we would be <UNK> by now </s> </s> </s>\n",
      "<s> <s> <s> <UNK> jello shot </s> </s> </s>\n",
      "<s> <s> <s> honestly now that im <UNK> about it this <UNK> be the <UNK> donna </s> </s> </s>\n",
      "<s> <s> <s> business <UNK> now and <UNK> </s> </s> </s>\n",
      "<s> <s> <s> oh no no thats too much too much <UNK> for me </s> </s> </s>\n",
      "<s> <s> <s> did someone call for a <UNK> cause <UNK> im <UNK> hey <UNK> </s> </s> </s>\n",
      "<s> <s> <s> i mean for everything </s> </s> </s>\n",
      "<s> <s> <s> what up my man <UNK> are you kidding me </s> </s> </s>\n",
      "<s> <s> <s> <UNK> <UNK> me two <UNK> <UNK> said it was the wrong house </s> </s> </s>\n",
      "<s> <s> <s> you cant <UNK> <UNK> of <UNK> and <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> <UNK> should be coming to us </s> </s> </s>\n",
      "<s> <s> <s> uhoh uhoh </s> </s> </s>\n",
      "<s> <s> <s> <UNK> to the n to the <UNK> of <UNK> </s> </s> </s>\n",
      "<s> <s> <s> he was a <UNK> </s> </s> </s>\n",
      "<s> <s> <s> she loved the <UNK> <UNK> do what he say and <UNK> be <UNK> </s> </s> </s>\n",
      "<s> <s> <s> no <UNK> </s> </s> </s>\n",
      "<s> <s> <s> name </s> </s> </s>\n",
      "<s> <s> <s> shes a <UNK> <UNK> </s> </s> </s>\n",
      "<s> <s> <s> its not for anything weird </s> </s> </s>\n",
      "<s> <s> <s> <UNK> in a <UNK> </s> </s> </s>\n",
      "<s> <s> <s> yeah i know i know </s> </s> </s>\n",
      "<s> <s> <s> <UNK> out it was the wrong house </s> </s> </s>\n",
      "<s> <s> <s> its like i always say okay </s> </s> </s> \n",
      "\n",
      "test corpus:  fourgram-Jean-Ralphio Saperstein-test.txt\n",
      "# of test sentences: 180\n",
      "Average probability: 2.697724413361318e-05\n",
      "Standard deviation: 9.173053973048989e-05\n"
     ]
    }
   ],
   "source": [
    "create_and_train_stat_model(jean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
